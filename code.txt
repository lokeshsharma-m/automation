image caption -output--rag based llm model



import transformers

from transformers import AutoProcessor, Blip2ForConditionalGeneration
import torch

import requests
from PIL import Image
from transformers import Blip2Processor,Blip2ForConditionalGeneration

device = "cuda" if torch.cuda.is_available() else "cpu"


processor = Blip2Processor.from_pretrained("Salesforce/blip2-opt-2.7b")
model = Blip2ForConditionalGeneration.from_pretrained("Salesforce/blip2-opt-2.7b")
model.to(device)

url = 'https://media.newyorker.com/cartoons/63dc6847be24a6a76d90eb99/master/w_1160,c_limit/230213_a26611_838.jpg'
image = Image.open(requests.get(url, stream=True).raw).convert('RGB')  
display(image)

type(image)


inputs = processor(image, return_tensors="pt").to(device)

generated_ids = model.generate(**inputs)
generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()
print(generated_text)


prompt = "Question: How many monsters are there? Answer:"

inputs = processor(image, text=prompt, return_tensors="pt").to(device)

generated_ids = model.generate(**inputs)
generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()
print(generated_text)

image=Image.open('')
image_my











######code################

pip install git+https://github.com/huggingface/transformers.git

pip install torch 

import transformers

from transformers import AutoProcessor, Blip2ForConditionalGeneration
import torch

pip install Pillow

import requests
import PIL
from PIL import Image
from transformers import Blip2Processor,Blip2ForConditionalGeneration

device = "cuda" if torch.cuda.is_available() else "cpu"

processor = Blip2Processor.from_pretrained("Salesforce/blip2-opt-2.7b")
model = Blip2ForConditionalGeneration.from_pretrained("Salesforce/blip2-opt-2.7b")
model.to(device)

# url = 'https://media.newyorker.com/cartoons/63dc6847be24a6a76d90eb99/master/w_1160,c_limit/230213_a26611_838.jpg'
# url = 'https://www.splashlearn.com/math-vocabulary/wp-content/uploads/2022/10/Bar-Graph-1-1.png'
url="http://images.cocodataset.org/val2017/000000039769.jpg"
image = Image.open(requests.get(url, stream=True).raw) 
display(image)

type(image)

inputs = processor(image, return_tensors="pt").to(device)

generated_ids = model.generate(**inputs)
generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()
print(generated_text)

prompt = "Question:what is the cat doing? Answer: "

inputs = processor(image, text=prompt, return_tensors="pt").to(device)

generated_ids = model.generate(**inputs,max_new_tokens=51)
generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()
print(generated_text)

context = [
   ("how many students like caramel flavor?", "10"),
   ("how many flavors are there in the image?", "4")
]
question = "What is most popular flavor ?"
template = "Question: {} Answer: {}."

prompt = " ".join([template.format(context[i][0], context[i][1]) for i in range(len(context))]) + " Question: " + question + " Answer:"

print(prompt)

FeedBack 1:

Describe the nature of the work I did with/for you:
Lokesh worked with me on deploying and testing an image captioning model using AI/ML techniques. 
His responsibilities included working on various aspects of the model development, 
from data preparation to model evaluation, and ensuring that the project objectives were met within the timeline.

Based on your observation, what did I do well:
Lokesh excelled in understanding the complexities of the project. He was very effective in troubleshooting issues during
 the model training phase and was always open to discussing new ideas and approaches. 
His willingness to collaborate and his attention to detail helped ensure that the project stayed on track.

Based on your observation, what could I have done better?
While lokesh was great at managing the technical aspects, there could have been more focus on documenting the 
process as we went along. Having more detailed documentation would have helped onboard others faster and made 
troubleshooting easier in the long run. Improved communication on small changes might have also kept us even more aligned.


FeedBack 2:

Describe the nature of the work I did with/for you:
Lokesh collaborated with me on the development of an AI/ML proof of concept for image captioning. As the scrum master, 
he ensured that the team followed agile practices and maintained clear communication throughout the project. In addition 
to managing sprints, Lokesh also contributed to the technical side by supporting the training and evaluation of the model.

Based on your observation, what did I do well:
Lokesh did an excellent job in balancing his responsibilities as a scrum master while contributing 
to the technical aspects of the project. He facilitated effective meetings, kept the team aligned on goals and His technical 
input during the model development phase was also valuable, as he helped troubleshoot issues and ensure progress was steady.

What could I have done better:
Lokesh tends to take initiative and often works independently, which is a great strength.
 However, occasionally reaching out for help or collaborating more closely with others could make tasks more
 efficient and allow for sharing of diverse ideas. Embracing team support and feedback more readily could lead to 
even stronger outcomes.

